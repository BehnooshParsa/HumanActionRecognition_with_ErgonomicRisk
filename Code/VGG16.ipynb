{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "# from keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Helper-function for joining a directory and list of filenames.\n",
    "def path_join(dirname, filenames):\n",
    "    return [os.path.join(dirname, filename) for filename in filenames]\n",
    "\n",
    "### Helper-function for plotting images\n",
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 1)\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # There may be less than 9 images, ensure it doesn't crash.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i],\n",
    "                      interpolation=interpolation)\n",
    "\n",
    "            # Name of the true class.\n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true_name)\n",
    "            else:\n",
    "                # Name of the predicted class.\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "### Helper-function for printing confusion matrix\n",
    "# Import a function from sklearn to calculate the confusion-matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    \n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "    np.savetxt('Confusion_matrix_20cls.txt', cm)\n",
    "    # Print the class-names for easy reference.\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(\"({0}) {1}\".format(i, class_name))\n",
    "\n",
    "### Helper-function for plotting example errors\n",
    "def plot_example_errors(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Boolean array whether the predicted class is incorrect.\n",
    "    incorrect = (cls_pred != cls_test)\n",
    "\n",
    "    # Get the file-paths for images that were incorrectly classified.\n",
    "    image_paths = np.array(image_paths_test)[incorrect]\n",
    "\n",
    "    # Load the first 9 images.\n",
    "    images = load_images(image_paths=image_paths[0:3])\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = cls_test[incorrect]\n",
    "    \n",
    "    # Plot the 9 images we have loaded and their corresponding classes.\n",
    "    # We have only loaded 9 images so there is no need to slice those again.\n",
    "    plot_images(images=images,\n",
    "                cls_true=cls_true[0:3],\n",
    "                cls_pred=cls_pred[0:3])\n",
    "\n",
    "def example_errors():\n",
    "    # The Keras data-generator for the test-set must be reset\n",
    "    # before processing. This is because the generator will loop\n",
    "    # infinitely and keep an internal index into the dataset.\n",
    "    # So it might start in the middle of the test-set if we do\n",
    "    # not reset it first. This makes it impossible to match the\n",
    "    # predicted classes with the input images.\n",
    "    # If we reset the generator, then it always starts at the\n",
    "    # beginning so we know exactly which input-images were used.\n",
    "    generator_test.reset()\n",
    "    \n",
    "    # Predict the classes for all images in the test-set.\n",
    "    y_pred = new_model.predict_generator(generator_test,\n",
    "                                         steps=steps_test)\n",
    "\n",
    "    # Convert the predicted classes from arrays to integers.\n",
    "    cls_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "    # Plot examples of mis-classified images.\n",
    "    plot_example_errors(cls_pred)\n",
    "    \n",
    "    # Print the confusion matrix.\n",
    "    print_confusion_matrix(cls_pred)\n",
    "\n",
    "### Helper-function for loading images\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [plt.imread(path) for path in image_paths]\n",
    "\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)\n",
    "\n",
    "### Helper-function for plotting training history\n",
    "def plot_training_history(history):\n",
    "    # Get the classification accuracy and loss-value\n",
    "    # for the training-set.\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "\n",
    "    # Get it for the validation-set (we only use the test-set).\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Plot the accuracy and loss-values for the training-set.\n",
    "    fig=plt.figure()\n",
    "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
    "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
    "    \n",
    "    # Plot it for the test-set.\n",
    "    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
    "    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
    "\n",
    "    # Plot title and legend.\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Ensure the plot shows correctly.\n",
    "    plt.show()\n",
    "    fig.savefig('errors_20cls.png')\n",
    "    fig.savefig('errors_20cls.eps')\n",
    "\n",
    "## Example Predictions: \n",
    "# We need a helper-function for loading and resizing an image \n",
    "# so it can be input to the VGG16 model,\n",
    "# as well as doing the actual prediction and showing the result.\n",
    "def predict(image_path):\n",
    "    # Load and resize the image using PIL.\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img_resized = img.resize(input_shape, PIL.Image.LANCZOS)\n",
    "\n",
    "    # Plot the image.\n",
    "    plt.imshow(img_resized)\n",
    "    plt.show()\n",
    "\n",
    "    # Convert the PIL image to a numpy-array with the proper shape.\n",
    "    img_array = np.expand_dims(np.array(img_resized), axis=0)\n",
    "\n",
    "    # Use the VGG16 model to make a prediction.\n",
    "    # This outputs an array with 1000 numbers corresponding to\n",
    "    # the classes of the ImageNet-dataset.\n",
    "    pred = model.predict(img_array)\n",
    "    \n",
    "    # Decode the output of the VGG16 model.\n",
    "    pred_decoded = decode_predictions(pred)[0]\n",
    "\n",
    "    # Print the predictions.\n",
    "    for code, name, score in pred_decoded:\n",
    "        print(\"{0:>6.2%} : {1}\".format(score, name))\n",
    "\n",
    "## Helper-function for printing whether a layer in the VGG16 model should be trained.\n",
    "def print_layer_trainable():\n",
    "    for layer in conv_model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './Train_Valid/train/'\n",
    "test_dir = './Train_Valid/valid/'\n",
    "print('train_dir:',train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Pre-Trained Model: VGG16\n",
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "input_shape = model.layers[0].output_shape[1:3]\n",
    "print('input_shape:',input_shape)\n",
    "# rotation_range=180,zoom_range=[0.9, 1.5],\n",
    "datagen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.05,\n",
    "      shear_range=0.1,\n",
    "      horizontal_flip=False,\n",
    "      vertical_flip=False,\n",
    "      fill_mode='nearest')\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 20\n",
    "# We can save the randomly transformed images during training, \n",
    "# so as to inspect whether they have been overly distorted,\n",
    "# so we have to adjust the parameters for the data-generator above.\n",
    "if True:\n",
    "    save_to_dir =None\n",
    "else:\n",
    "    save_to_dir='./augmented_images/'\n",
    "\n",
    "print(save_to_dir)\n",
    "print('training set:')\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    save_to_dir=save_to_dir)\n",
    "\n",
    "print('test set:')\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "steps_test = generator_test.n / batch_size\n",
    "print('steps_test:', steps_test)\n",
    "\n",
    "image_paths_train = path_join(train_dir, generator_train.filenames)\n",
    "image_paths_test = path_join(test_dir, generator_test.filenames)\n",
    "\n",
    "cls_train = generator_train.classes\n",
    "cls_test = generator_test.classes\n",
    "\n",
    "class_names = list(generator_train.class_indices.keys())\n",
    "\n",
    "num_classes = generator_train.num_classes\n",
    "print('num_classes:', num_classes)\n",
    "\n",
    "# Compute class weights\n",
    "class_weight = compute_class_weight(class_weight='balanced',\n",
    "                                    classes=np.unique(cls_train),\n",
    "                                    y=cls_train)\n",
    "\n",
    "print('class_weight:', class_weight)\n",
    "print('class_names:\\n',class_names)\n",
    "\n",
    "print('Model summary:')\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a new model with the pretrained VGG16 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_layer = model.get_layer('block5_pool')\n",
    "print('Transfer_layer output:\\n',transfer_layer.output)\n",
    "dataset= ['UW_IOM'][0]\n",
    "conv_model = Model(inputs=model.input,\n",
    "                   outputs=transfer_layer.output)\n",
    "\n",
    "# Define the trainable layers\n",
    "conv_model.trainable = False\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "print_layer_trainable()\n",
    "\n",
    "new_model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG16 model from above.\n",
    "new_model.add(conv_model)\n",
    "\n",
    "new_model.add(Flatten())\n",
    "\n",
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "# Add the final layer for the actual classification.\n",
    "new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=1e-7)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['categorical_accuracy']\n",
    "\n",
    "\n",
    "## we need to compile the model for the changes to take effect.\n",
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "print('Model summary:')\n",
    "print(new_model.summary())\n",
    "\n",
    "plot_model(new_model, to_file='VGG_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps_per_epoch = 10\n",
    "\n",
    "history = new_model.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  class_weight=class_weight,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "from os import path\n",
    "if not path.exists('./Models'):\n",
    "    try:  \n",
    "        os.mkdir('./Models')\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % './Models')\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s \" % './Models')\n",
    "model_yaml = new_model.to_yaml()\n",
    "with open(\"./Models/VGG16model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "new_model.save_weights(\"./Models/VGG16model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on few examples and save the confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = new_model.evaluate_generator(generator_test, steps=steps_test)\n",
    "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))\n",
    "example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(model_, dataset, featureType):\n",
    "    saving_path = './Features/'+ str(dataset) + '/' + str(featureType)\n",
    "    frames_folder_path='./Frames/'\n",
    "#     feature_extractor = Model(inputs=model_.input, outputs=model_.get_layer('dense').output)\n",
    "    feature_extractor = Model(inputs=model_.input, outputs=model_.layers[2].output) #first fc layer\n",
    "    \n",
    "    if not os.path.isdir(saving_path):\n",
    "                os.makedirs(saving_path)\n",
    "    input_shape = feature_extractor.input_shape[1:3] #[224,224]#np.array([224,224])\n",
    "    print(frames_folder_path)\n",
    "    print('input_shape:',input_shape)        \n",
    "    for i, folder in enumerate(os.listdir(frames_folder_path)):\n",
    "        print('video',folder)\n",
    "        frame_path = os.path.join(frames_folder_path,folder) #this is the frame path\n",
    "        feature_vector = np.zeros([1024,len(os.listdir(frame_path))])\n",
    "#         print(np.shape(feature_vector))\n",
    "        FFF=[];\n",
    "        for j, frame_ in enumerate(sorted(os.listdir(frame_path))):\n",
    "            FFF.append(frame_[:-4])\n",
    "        FFF = sorted(FFF, key=int)\n",
    "#         print(FFF)\n",
    "        for j, frame_ in enumerate(FFF):\n",
    "#             print('frame',frame_)\n",
    "            image_path = os.path.join(frame_path,frame_+'.jpg')\n",
    "            # Load and resize the image using PIL.\n",
    "            img = PIL.Image.open(image_path)\n",
    "            img_resized = img.resize(input_shape, PIL.Image.LANCZOS)\n",
    "            # Convert the PIL image to a numpy-array with the proper shape.\n",
    "            img_array = np.expand_dims(np.array(img_resized), axis=0)\n",
    "            # generate feature [1024]\n",
    "            features = feature_extractor.predict(img_array)\n",
    "            features = np.squeeze(features)\n",
    "### ********************* Edit here ********************** ###\n",
    "            feature_vector[:,j] = features\n",
    "        # original length features\n",
    "        feature_vector = feature_vector.T\n",
    "        # To triplicate the features by experiment\n",
    "#         feature_vector = np.tile(feature_vector.T,(3,1))\n",
    "        # To triplicate the features framewise\n",
    "#         print(np.shape(feature_vector))\n",
    "#         feature_vector = np.repeat(feature_vector,3,axis=1).T\n",
    "        print(np.shape(feature_vector))\n",
    "        np.save(saving_path+folder,feature_vector)\n",
    "        # saves as .cvs\n",
    "#         np.savetxt(saving_path+folder+'.csv', feature_vector, delimiter=\",\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and make sure that you did it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YAML and create model\n",
    "model_name ='VGG16model'\n",
    "featureType=['PreTrained','FineTuned45'][0]\n",
    "# \\Data\\UW_dataset\\Saved-models\\Amazon_VGG16model_1024_UW_500_300\n",
    "yaml_file = open('./Models/'+model_name+'.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights('./Models/'+model_name+'.h5')\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "optimizer = Adam(lr=1e-5)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['categorical_accuracy']\n",
    "\n",
    "\n",
    "## we need to compile the model for the changes to take effect.\n",
    "loaded_model.compile(loss=loss,optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "print('Model summary:')\n",
    "print(loaded_model.summary())\n",
    "# loaded_model.compile(loss='categorical_crossentropy', optimizer='ADAMS', metrics=['accuracy'])\n",
    "## Define the test generator\n",
    "train_dir = './Train_Valid/train/'\n",
    "test_dir = './Train_Valid/valid/'\n",
    "\n",
    "input_shape = loaded_model.input.shape[1:3]\n",
    "print('input_shape:',input_shape)\n",
    "# rotation_range=180,zoom_range=[0.9, 1.5],\n",
    "datagen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      horizontal_flip=False,\n",
    "      vertical_flip=False,\n",
    "      fill_mode='nearest')\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 20\n",
    "# We can save the randomly transformed images during training, \n",
    "# so as to inspect whether they have been overly distorted,\n",
    "# so we have to adjust the parameters for the data-generator above.\n",
    "if True:\n",
    "    save_to_dir =None\n",
    "else:\n",
    "    save_to_dir='.augmented_images/'\n",
    "\n",
    "print(save_to_dir)\n",
    "print('training set:')\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    save_to_dir=save_to_dir)\n",
    "\n",
    "print('test set:')\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "steps_test = generator_test.n / batch_size\n",
    "print('steps_test:', steps_test)\n",
    "\n",
    "result = loaded_model.evaluate_generator(generator_test, steps=steps_test)\n",
    "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "ExtractFeatures(loaded_model, dataset, featureType)\n",
    "elapsed = time.time() - t\n",
    "print('Time elapsed: ', elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
